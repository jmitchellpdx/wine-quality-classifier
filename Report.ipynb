{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b9838aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d85816",
   "metadata": {},
   "source": [
    "# Wine Quality Classifier\n",
    "\n",
    "**MSDS 5509 Machine Learning 1 - Final Project**\n",
    "\n",
    "John Mitchell  \n",
    "University of Colorado at Boulder MSDS Program  \n",
    "*john.mitchell@colorado.edu*\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This supervised learning project develops a binary classifier to distinguish between regular and premium wines - in terms of their taste quality - based on their chemical composition. The project makes use of the UCI Wine Quality dataset, which contains thousands of wine samples from Portugal, including both red and white varieties. Each wine sample includes chemical features such as acidity levels, alcohol content, and residual sugar, along with quality assessments from wine experts.\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "Wine quality in the dataset is rated on a scale from 0 to 10, where 0 represents very poor quality and 10 represents excellent quality. In practice, the observed quality ratings range from 3 to 9. \n",
    "\n",
    "For this classification task, wines are categorized into two groups:\n",
    "\n",
    "- **Regular wines**: Quality ratings of 6 or below\n",
    "- **Premium wines**: Quality ratings of 7, 8, or 9\n",
    "\n",
    "This classification problem has a potential application in the wine industry: wine importers and distributors could use such a classifier to help find premium wines more efficiently. \n",
    "\n",
    "## Project Goals\n",
    "\n",
    "The primary objectives of this project are:\n",
    "\n",
    "1. **Data Investigation**: Clean and conduct an Exploratory Data Analysis (EDA) to prepare features for input to several classifiers.\n",
    "2. **Infrastructure Building**: Develop a basic machine learning pipeline to allow the data to be fed into several models, search for the best model in each case, and compare the best models.\n",
    "3. **Model Evaluation**: Explore the performance of several models both from within this course and from other courses, specifically:\n",
    "    - Logistic Regression (as a baseline linear classifier)\n",
    "    and several nonlinear models:\n",
    "    - Support Vector Machine (SVM)\n",
    "    - Random Forest\n",
    "    - Multi-Layer Perceptron (MLP) (or feedforward neural network), which I used in the NLP (Natural Language Processing) course sequence (#5747, #5748)\n",
    "4. **Results Analysis**: Compare model performance using appropriate metrics, evaluate and interpret the results\n",
    "5. **Practical Significance**: Investigate the practical significance of these results - could they be useful in the wine business?\n",
    "\n",
    "More generally, I hoped that the process would give me insights into the complete supervised learning project lifecycle - and tools to take to future projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967689ef",
   "metadata": {},
   "source": [
    "# The Wine Dataset\n",
    "\n",
    "## Data Source and Citation\n",
    "\n",
    "The dataset originates from the UCI Machine Learning Repository. It was used in an early paper on using machine learning models (Cortez et al., 2009). In their paper, they focused on regression (predicting the wine quality level) rather than classification. In publishing the data to the repository, the authors expressed the hope that it would be a useful dataset for other researchers.\n",
    "\n",
    "## Dataset Description\n",
    "\n",
    "The dataset contains samples of Portuguese \"Vinho Verde\" wine variants, including both red and white wines. The dataset includes only \"physicochemical\" (physical and/or chemical) properties as input features. The target variable is quality ratings. \n",
    "\n",
    "Information such as the wine brand, grape variety, or pricing is not part of the dataset.\n",
    "\n",
    "**Dataset Size:**\n",
    "- Red wine samples: 1,599\n",
    "- White wine samples: 4,898  \n",
    "- Total combined samples: 6,497 rows\n",
    "- Features: 11 physicochemical attributes plus quality rating\n",
    "- Missing values: None reported in original dataset\n",
    "\n",
    "**Input Features:**\n",
    "These features are all continuous-valued. Units are in parentheses.\n",
    "1. Fixed acidity (g/dm³)  \n",
    "2. Volatile acidity (g/dm³)  \n",
    "3. Citric acid (g/dm³)  \n",
    "4. Residual sugar (g/dm³)  \n",
    "5. Chlorides (g/dm³)  \n",
    "6. Free sulfur dioxide (mg/dm³)  \n",
    "7. Total sulfur dioxide (mg/dm³)  \n",
    "8. Density (g/cm³)  \n",
    "9. pH (unitless)  \n",
    "10. Sulphates (g/dm³)  \n",
    "11. Alcohol content (% by volume)  \n",
    "\n",
    "**Target Variable:**\n",
    "- Quality: Wine quality ratings from 0 (very poor) to 10 (excellent). The data only contained values from 3 to 9.\n",
    "- The scores were median scores from three wine expert evaluations, and thus were integers.\n",
    "\n",
    "**How Variables Will Be Referred to in the Report:**\n",
    "I have used the convention of `highlighting` variables or quality levels when referring to them in a technical sense. So for example, the quality level `premium` will be highlighted if I am referring to that target value specifically, but \"premium wines\" (not highlighted) if just discussing the idea of premium wines generally. Python functions for displaying tables do not always capitalize variable names consistently, so I have just used the same capitalization as the tool or table being discussed - so the feature may be `residual sugar` or `Residual Sugar` depending on context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa2e83",
   "metadata": {},
   "source": [
    "# Data Cleaning \n",
    "\n",
    "## Data Preparation and Feature Engineering\n",
    "\n",
    "For this project, I combined the red and white wine datasets and added a `wine_type` feature (red: 0, white: 1) to preserve the distinction between wine varieties. This is used as an additional feature in the wine classifier, as wine type (red/white) may potentially be relevant to predicting quality. \n",
    "\n",
    "## Missing Value Assessment\n",
    "\n",
    "I verified that there were no missing values in the combined wine dataset - confirming the authors' original claim. This eliminated the need for any missing value imputation.  \n",
    "\n",
    "## Duplicate Detection and Removal\n",
    "\n",
    "When checking for data quality issues, I discovered a significant problem not mentioned in the original research: there were over 1,000 (specifically, 1,177) duplicate rows in the combined dataset. Each duplicate contained identical values across all features and the same quality rating.\n",
    "\n",
    "After researching data's provenance, I decided these duplicates were highly unlikely to represent legitimate identical measurements. The absence of any indexing or identification information in the dataset suggested potential errors during data collection or combination.\n",
    "\n",
    "This assessment was reinforced by discovering two other projects - based on this dataset - that identified the same duplicate issue (Bunevičius, V. 2019,Ijemuah, V. 2020). These researchers also chose to remove duplicates before analysis.\n",
    "\n",
    "Consequently, I removed all duplicate entries from the dataset as part of the cleaning process, reducing the number of examples from 6,497 to 5,320. The bar plot below shows the totals for each wine type before and after duplicate removal. There were proprortionately more white wines removed.\n",
    "\n",
    "![Wine Totals Before and After Duplicate removal](figures/wine_type_chart_2.png)  \n",
    "*Wine Totals Before and After Duplicate removal*\n",
    "\n",
    "For the rest of the EDA, and for the subsequent modeling, the data set without duplicates will be used.\n",
    "\n",
    "## Outlier Analysis\n",
    "\n",
    "As I explored outliers, I kept in mind that this data has been used before in a peer-reviewed study and thus is likely to have been pre-screened for outliers that are errors, as opposed to unusual but valid measurements. \n",
    "\n",
    "First, how common are outliers? Below is a tally of outliers for all features. I used the IQR (Inter-Quartile Range) method that is more robust to non-normality: that is, outliers are outside the range:\n",
    "- lower bound: Q1 - 1.5 × IQR\n",
    "- upper bound: Q3 + 1.5 × IQR\n",
    "\n",
    "Where the IQR is Q3-Q1, the difference between the third and first quartiles.\n",
    "\n",
    "The features varied widely in the number of outliers. The `Alcohol` feature had just one, whereas `Fixed Acidity` had over 300. \n",
    "\n",
    "| Feature | Outlier Count | Outlier % |\n",
    "|---------|---------------|-----------|\n",
    "| Fixed acidity | 304 | 5.7% |\n",
    "| Volatile acidity | 279 | 5.2% |\n",
    "| Citric acid | 143 | 2.7% |\n",
    "| Residual sugar | 141 | 2.7% |\n",
    "| Chlorides | 237 | 4.5% |\n",
    "| Free sulfur dioxide | 44 | 0.8% |\n",
    "| Total sulfur dioxide | 10 | 0.2% |\n",
    "| Density | 3 | 0.1% |\n",
    "| pH | 49 | 0.9% |\n",
    "| Sulphates | 163 | 3.1% |\n",
    "| Alcohol | 1 | 0.0% |\n",
    "\n",
    "I then explored each feature with a boxplot. A representative sample of features is shown below.\n",
    "\n",
    "![Feature Boxplots](figures/outlier_boxplots.png)\n",
    "*Boxplots for a Representative Sample of Features*\n",
    "\n",
    "Insights from boxplots:\n",
    "- Most features have outliers in a similar pattern to `Chlorides` or `Residual Sugar`: that is, a cluster of outliers in the upper tail.\n",
    "- The `Alcohol` and `Density` features, on the other hand, have very few outliers. Unusual values of these features are very rare.\n",
    "- Finally, the `pH` feature is the only feature with outliers in both tails.\n",
    "\n",
    "Are any of these outliers unrealistic, as opposed to unusual? To explore whether the outliers were unusual but realistic in the context of wine production, I asked an AI engine (Claude Opus 4.1) to research realistic values for wines and summarize. Here are the findings. \n",
    "\n",
    "| Feature | Units | Realistic Min | Realistic Max | Notes |\n",
    "|---------|-------|---------------|---------------|-------|\n",
    "| Fixed acidity | g/dm³ | 3.0 | 18.0 | Very low acid wines exist; high-acid wines can reach 15-18 |\n",
    "| Volatile acidity | g/dm³ | 0.08 | 2.0 | >1.2 typically considered faulty, but some exist up to 2.0 |\n",
    "| Citric acid | g/dm³ | 0.0 | 1.5 | Can be completely absent; rarely exceeds 1.0-1.2 naturally |\n",
    "| Residual sugar | g/dm³ | 0.5 | 65.0 | Dry wines ~1-4; dessert wines can exceed 50-60 |\n",
    "| Chlorides | g/dm³ | 0.01 | 1.0 | Very pure wines <0.05; salty/faulty wines can reach 0.8+ |\n",
    "| Free sulfur dioxide | mg/dm³ | 1.0 | 150.0 | Legal limits vary; over-sulfured wines can hit 100-150 |\n",
    "| Total sulfur dioxide | mg/dm³ | 10.0 | 400.0 | Must be ≥ free SO2; heavily sulfured wines reach 300+ |\n",
    "| Density | g/cm³ | 0.985 | 1.010 | High sugar/alcohol affects density significantly |\n",
    "| pH | unitless | 2.7 | 4.2 | Very acidic wines ~2.8; low-acid wines can hit 4.0+ |\n",
    "| Sulphates | g/dm³ | 0.2 | 2.5 | Natural minimum ~0.3; heavily treated wines reach 2.0+ |\n",
    "| Alcohol | % vol | 7.0 | 16.5 | Legal minimums vary; fortified-style can reach 16% |\n",
    "\n",
    "These limits indicate that even the extreme outliers (such as the value of `Residual Sugar` above 60 visible in its boxplot) are plausible. \n",
    "\n",
    "Since no outliers were so extreme as to be unrealistic, none were removed. \n",
    "\n",
    "## Data Cleaning Summary\n",
    "\n",
    "- The two raw datasets (red and white wines) were combined, and a binary `wine_type` (0=red, 1=white) added. \n",
    "- There were no missing values in the dataset for any of the features, or for the target.\n",
    "- However, 1,177 examples (17% of the total) were duplicates, of uncertain provenance, though most likely from errors in merging datasets. These were removed.\n",
    "- Outliers: outliers were found to be within plausible values, and thus none were removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6456933",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "I performed an EDA on the dataset, exploring features, the target, and interactions (correlations, multicollinearity). This section discusses the results of the EDA. At the end of the section, the essential takeaways for the modeling stage are summarized.\n",
    "\n",
    "## Feature Summary Statistics and Distributions\n",
    "\n",
    "The mean, standard deviation, and a 5-number summary (min, Q1, median, Q3, max) are in the table below. \n",
    "\n",
    "|       |   Fixed Acidity |   Volatile Acidity |   Citric Acid |   Residual Sugar |   Chlorides |   Free Sulfur Dioxide |   Total Sulfur Dioxide |   Density |        pH |   Sulphates |   Alcohol |\n",
    "|:------|----------------:|-------------------:|--------------:|-----------------:|------------:|----------------------:|-----------------------:|----------:|----------:|------------:|----------:|\n",
    "| count |       5320      |          5320      |     5320      |        5320      |   5320      |             5320      |              5320      | 5320      | 5320      |   5320      | 5320      |\n",
    "| mean  |          7.2152 |             0.3441 |        0.3185 |           5.0485 |      0.0567 |               30.0367 |               114.109  |    0.9945 |    3.2247 |      0.5334 |   10.5492 |\n",
    "| std   |          1.3197 |             0.1682 |        0.1472 |           4.5002 |      0.0369 |               17.805  |                56.7742 |    0.003  |    0.1604 |      0.1497 |    1.1859 |\n",
    "| min   |          3.8    |             0.08   |        0      |           0.6    |      0.009  |                1      |                 6      |    0.9871 |    2.72   |      0.22   |    8      |\n",
    "| 25%   |          6.4    |             0.23   |        0.24   |           1.8    |      0.038  |               16      |                74      |    0.9922 |    3.11   |      0.43   |    9.5    |\n",
    "| 50%   |          7      |             0.3    |        0.31   |           2.7    |      0.047  |               28      |               116      |    0.9946 |    3.21   |      0.51   |   10.4    |\n",
    "| 75%   |          7.7    |             0.41   |        0.4    |           7.5    |      0.066  |               41      |               153.25   |    0.9968 |    3.33   |      0.6    |   11.4    |\n",
    "| max   |         15.9    |             1.58   |        1.66   |          65.8    |      0.611  |              289      |               440      |    1.039  |    4.01   |      2      |   14.9    |\n",
    "\n",
    "Observations:\n",
    "\n",
    "- Features are non-negative (as would be expected from physical and chemical measurements). However, some have zero values. This will need to be factored in if the feature is log transformed to adjust for skew.\n",
    "- Features vary widely in their ranges, ranging from `density` (very tightly clustered around 1) to `total sulfur dioxide` (which ranges from 6 to 440). Scaling will be applied prior to modeling to standardize. \n",
    "- The table verifies that there are no missing values, and that duplicates have indeed been removed. \n",
    "\n",
    "Next, the distribution of each feature is explored. Histograms are below.\n",
    "\n",
    "![Feature Histograms](figures/feature_distributions.png)\n",
    "*Histograms for Features. Wine Type (a binary feature) is not shown*\n",
    "\n",
    "While some features appear roughly symmetric, several (especially `chlorides` and `residual sugar`) appear to be significantly positively skewed, and thus may need to be transformed prior to scaling. The features are ranked by skew in the table below. Those with skew above 1 are significantly skewed. \n",
    "\n",
    "Feature Skewness:\n",
    "| Feature              |   Skewness |\n",
    "|:---------------------|-----------:|\n",
    "| chlorides            |  5.33824   |\n",
    "| sulphates            |  1.80945   |\n",
    "| residual sugar       |  1.70655   |\n",
    "| fixed acidity        |  1.65042   |\n",
    "| volatile acidity     |  1.50456   |\n",
    "| free sulfur dioxide  |  1.36272   |\n",
    "| density              |  0.666326  |\n",
    "| alcohol              |  0.545696  |\n",
    "| citric acid          |  0.484309  |\n",
    "| pH                   |  0.389969  |\n",
    "| total sulfur dioxide |  0.0636144 |\n",
    "\n",
    "I explored transforming the six highly skewed features. A log transform turned out to be effective. The log-transformed features are below. Note that `residual sugar` is now bimodal (which is acceptable for modeling, as long as it is roughly symmetric) and `free sulfur dioxide` is now negatively skewed (but less so than before).\n",
    "\n",
    "![Transformed Feature Histograms](figures/transformed_feature_distributions.png)\n",
    "*Features after Log Transformation*\n",
    "\n",
    "However, the skews now have absolute values less than one:\n",
    "\n",
    "| Feature              |   Skewness |\n",
    "|:---------------------|-----------:|\n",
    "| chlorides            |     0.9067 |\n",
    "| fixed acidity        |     0.8431 |\n",
    "| density              |     0.6663 |\n",
    "| alcohol              |     0.5457 |\n",
    "| citric acid          |     0.4843 |\n",
    "| sulphates            |     0.394  |\n",
    "| pH                   |     0.39   |\n",
    "| volatile acidity     |     0.3304 |\n",
    "| residual sugar       |     0.3265 |\n",
    "| total sulfur dioxide |     0.0636 |\n",
    "| free sulfur dioxide  |    -0.7893 |\n",
    "\n",
    "Next, the target variable - wine quality ratings - is explored.\n",
    "\n",
    "## Exploring the Target Variable\n",
    "\n",
    "The raw wine quality scores have a very imbalanced distribution, with most values being in the 6 to 9 range. The distribution is shown below. \n",
    "\n",
    "![Totals with each wine quality score](figures/original_quality_counts.png)  \n",
    "*Total count for each wine quality score (3-9)*\n",
    "\n",
    "When I was initially exploring how to use the data set for wine classification, this imbalance caused problems. For example, splitting the data into poor (3,4), average (5-7), and good (8 to 9) resulted in so many examples in the 'average' category that the models could appear to be performing well by simply classifying most wines as average. \n",
    "\n",
    "I explored how to bucket the scores in a way would have a useful business purpose while addressing the class imbalance issue. I decided on a binary classification problem: identifying \"regular wines\" (quality 6 or less) versus \"premium\" wines (quality 7 or more). The \"premium\" wines are wines rated as above average by experts, and therefore could be priced higher. \n",
    "\n",
    "This split resulted in approximately 19% premium wines and 81% regular wines (figure below). While still imbalanced, this ratio should provide sufficient samples in both classes for the models to extract useful results. The figure below shows the number of examples in each quality category.\n",
    "\n",
    "![Class Proportions in Regular (6 or less) and Premium (7 or more)](figures/binary_quality_percentages.png)  \n",
    "*Proportions for Binary Class Split into Regular and Premium*\n",
    "\n",
    "## Relationships\n",
    "\n",
    "A correlation heatmap (below) was used to explore linear relationships between feature pairs, where absolute values close to 1 indicate a strong correlation. The highest correlation (0.72) occurred between `total sulfur dioxide` and `free sulfur dioxide`. Since total sulfur includes the free component, it is not surprising there is some correlation between the two. There is also a high correlation between density and alcohol (-0.67). Most other correlations are low - below 0.5 - but the fact that some of the variables are even weakly correlated suggests that there is some potential structure there for Logistic Regression.\n",
    "\n",
    "![Feature Correlation Heatmap](figures/feature_corrs.png)\n",
    "*Correlation Heatmap of Features. Duplicates above the diagonal are not shown.*\n",
    "\n",
    "I also calculated variance inflation factors (VIFs) to explore multicollinearity - that is, linear relationships not between individual pairs, but between one variable and some combination of the others (Faraway, 2014, pp. 106-109). A large VIF for a feature is an indication that it is highly multicollinear. There is no universally accepted cutoff value for defining \"high\" multicollinearity: I decided to use a conservative cutoff of 10.\n",
    "\n",
    "The VIFs of the unscaled data had some huge values (the largest - density - was over 900), but this turned out to be due to the small variance of density, which caused numerical instability in the VIF calculation. Using `StandardScaler` (mean zero, standard deviation one) resulted in the table below. \n",
    "\n",
    "| Feature | VIF |\n",
    "|---------|-----|\n",
    "| density | 14.92 |\n",
    "| residual sugar | 6.43 |\n",
    "| fixed acidity | 4.88 |\n",
    "| alcohol | 4.58 |\n",
    "| total sulfur dioxide | 2.93 |\n",
    "| pH | 2.48 |\n",
    "| free sulfur dioxide | 2.14 |\n",
    "| volatile acidity | 1.96 |\n",
    "| citric acid | 1.65 |\n",
    "| chlorides | 1.63 |\n",
    "| sulphates | 1.55 |\n",
    "\n",
    "Even using the conservative value of 10 for a high VIF, the `density` feature shows multicollinearity. I performed a brief domain research on why, using just a basic AI-assisted google search: since wine is composed of water, alcohol, and other dissolved compounds, its `density` is highly predictable from these features. In wine, it is also tightly clustered around the density of pure water of 1.0 g/cmÂ³, so the variance of `density` is low.\n",
    "\n",
    "## Feature-Target Relationship\n",
    "\n",
    "What about correlations between features and the target? A bar chart of correlations is below. \n",
    "\n",
    "![Feature Correlations with Quality](figures/feature_correlations_with_target.png)  \n",
    "*Feature Correlations with Wine Quality Target*\n",
    "\n",
    "The `density` and `alcohol` features have the highest correlations, both with absolute values in the moderate range (above 0.3 but under 0.5). Higher alcohol content - and lower density - are moderately predictive of wine quality. Other features are weakly correlated. \n",
    "\n",
    "## Modeling Takeaways from the EDA\n",
    "\n",
    "The EDA revealed several key insights to factor in during model fitting:\n",
    "\n",
    "- **Scale differences**: Features differ widely in their scale and should be standardized before using models that are scale-sensitive (such as SVM)\n",
    "- **Skewed features**: Several features are also highly skewed. Log transforming them reduced this issue, and this should be used prior to standard scaling\n",
    "- **Linear relationships**: Some moderate correlations were discovered within features, or between the feature and target. This suggests that there may be some linear patterning within the data for a Logistic Regression model\n",
    "- **Multicollinearity**: However, `density` exhibits multicollinearity. This could lead to instability in estimates for linear regression parameters. If this is a problem, remove `density`.\n",
    "- **Target class imbalance**: There are very few quality measures of low (3,4) and high (8,9) values. This leads to reframing the modeling problem into a binary classification problem with `regular` (6 or less) and `premium` (7 or more). Classes are still imbalanced (81%/19%) but there should be enough `premium` examples for model fitting.\n",
    "\n",
    "The next section explores model fitting with these insights in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548effd",
   "metadata": {},
   "source": [
    "# Models and Model Fitting\n",
    "\n",
    "To first briefly recap the goal: to find model(s) that - given a set of chemical features of wines - have \"some success\" on classifying wines into one of two classes: `regular` or `premium`.\n",
    "\n",
    "This section looks at:\n",
    "- The models that will be used\n",
    "- The Python modeling infrastructure to load and run model searches\n",
    "- How the data was split and transformed prior to modeling\n",
    "- Model tuning - finding the best of each type of model\n",
    "- A brief summary of results\n",
    "\n",
    "The next section on results and analysis will go deeper into model performance.\n",
    "\n",
    "## The Models \n",
    "\n",
    "I used several models covered in our course (**Logistic Regression**, **Support Vector Machine (SVM)** , **Random Forest**), as well as a **Multi-Layer Perceptron (MLP)** (also called a **feedforward neural network**) which I explored in the NLP courses (#5747, 5748). \n",
    "- Logistic Regression would serve as the baseline linear model.\n",
    "- Given the likely problem complexity, I felt it was important to explore a variety of non-linear models that work in different ways.\n",
    "\n",
    "## Modeling Infrastructure and Hardware\n",
    "\n",
    "Prior to the project, I developed a basic exploratory pipeline to run grid searches (using `GridSearchCV` in the `sklearn` package) of some or all of the models and compare the best results. \n",
    "\n",
    "The GitHub repo has the code. \n",
    "\n",
    "The core components of the pipeline are:\n",
    "- The `WineConfig` class that has a dictionary of parameter values to use for the grid search. Parameters were split into \"base\" parameters - that would stay constant during the model search, and \"grid\" parameters that would be varied. It also had a list of models to run. The default was all models ['rf', 'svm', 'logistic', 'mlp'], but this could be changed to run a search on a subset, or single model.\n",
    "- The `WineModelPipeline` reads this set of parameter values, runs a grid search for each model, and stores details of the best models and their performance. For the grid search, the parameters were passed into `GridSearchCV` as a dictionary. This function would then only use the parameters needed for that model.\n",
    "\n",
    "For simplicity, the results are saved in dataframes (rather than to files) and modeling and model evaluation were performed in the same notebook. Once the best models were obtained - after numerous iterations of modeling and evaluation using successively finer grids - the results were copied into the final report. A sample parameter grid is in Appendix B.\n",
    "\n",
    "The models were run on a laptop with GPU (Lenovo P16 Gen 2, 32 Cores,NVIDIA RTX 4000 Ada). None of the models can use the GPU, but all of them - except the MLP - can use multiple cores. While interpreting the results of each run and adjusting parameter values for each model for the next run was time-consuming, the grid searches themselves were not. A grid search with (say) 20-40 combinations for each model ran within 1-2 minutes (compared to 10-20 minutes without using multiple cores - the random forest was particularly time-consuming).\n",
    "\n",
    "## Data Splitting and Transformation Prior to Model Fitting\n",
    "\n",
    "- The data is split into 80% training, 20% testing. Models will be fit on the training data and evaluated on the test data\n",
    "- Five-fold cross validation will be used to monitor for overfitting\n",
    "- Because the target classes are imbalanced, the *weighted F1 score* will be used rather than *accuracy* as the primary driver of the grid search\n",
    "- For the models that support it (Logistic Regression, SVM, Random Forest), `class_weight='balanced'` is used to automatically adjust for class frequencies\n",
    "\n",
    "To create a level playing field, the same preprocessing was applied to the data for all models:\n",
    "\n",
    "- **Log transformation** of skewed features identified in the EDA to correct for skew (see EDA section)\n",
    "- **StandardScaler normalization** is applied to all features for algorithms sensitive to scale\n",
    "\n",
    "## Model Tuning: Finding the Best Models\n",
    "\n",
    "I started with coarse grids for all models and iterated with successively finer grids. In some cases (such as the Random Forest), I started with the most important parameters, then added others as I got close to the best model. Details for each model follow. In each, I give parameters which were fixed, either initially or after some exploration (with comments if there were other options), the hyperparameters, and the best values found. \n",
    "\n",
    "The scikit-learn reference has details of the models, their parameters, and tips on usage.\n",
    "\n",
    "### 1. Logistic Regression\n",
    "\n",
    "**Base Configuration:**\n",
    "\n",
    "- Penalty: L2 (Ridge) regularization. I used this to penalize more complex models, with the regularization strength C being the hyperparameter (see below).\n",
    "- Solver: 'saga' (Stochastic Average Gradient Augmented) - noted as a good general purpose solver with L2.\n",
    "- Max iterations: 1000. \n",
    "\n",
    "**Hyperparameter Tuning:**\n",
    "I started with a grid 'C' = [0.01, 0.1, 1, 10, 100]. Eventually, after multiple iterations, I found that C = 0.8 provided optimal performance. \n",
    "\n",
    "### 2. Support Vector Machine\n",
    "\n",
    "**Base Configuration:**\n",
    "- Kernel: A Radial Basis Function kernel was used for all searches. Using a linear function would have just given another linear classifier.\n",
    "\n",
    "**Hyperparameter Tuning:**\n",
    "The hyperparameters in this case are C and gamma:\n",
    "- Low values of C have a softer margin and thus higher tolerance for misclassification. Increasing C penalizes misclassification and results in a more complex decision boundary.\n",
    "- Gamma controls the radius of the kernels. Higher gamma results in more \"local\" kernels and thus more complex boundaries.\n",
    "\n",
    "The optimal values found - after several iterations of finer grids - were C = 2 and gamma = 0.8.\n",
    "\n",
    "### 3. Random Forest\n",
    "\n",
    "This ensemble decision tree model has several hyperparameters. I started with: \n",
    "- **n_estimators**: Number of trees in the ensemble\n",
    "- **max_depth**: Maximum tree depth\n",
    "- **max_features**: How many features to use in each tree. I explored both 'sqrt' and 'log' options, and found that 'sqrt' was better. I used this for the detailed searches.\n",
    "\n",
    "During finer searches, I added:\n",
    "- **min_samples_leaf**: The minimum examples to form a new leaf\n",
    "- **min_samples_split**: The minimum examples to split (that is, form a new subtree)\n",
    "\n",
    "The final optimal configuration used 55 trees, max_depth of 23, min_samples_leaf of 3, and min_samples_split of 4.\n",
    "\n",
    "### 4. Multi-Layer Perceptron (MLP)\n",
    "\n",
    "The model and its hyperparameters are discussed in chapter 11 of the course recommended reference (James et al., 2021). \n",
    "\n",
    "Briefly, the MLP passes weighted sums of the features through one or more internal (or hidden) layers, each of which applies nonlinear functions. Each hidden layer is composed of processors or \"neurons\" that take a weighted sum of their inputs, apply a nonlinear function, and pass the output on to the next layer. The final (or output) layer for a binary classification problem is a sigmoid function (similar to Logistic Regression). Training is performed using gradient descent methods: making small changes to the internal weights to reduce the error on the target. \n",
    "\n",
    "Thus, the hyperparameters are the internal structure of the MLP (number of layers and number of neurons each layer), the gradient descent method to use, and it's parameters.\n",
    "\n",
    "**Base Configuration:**\n",
    "- Max iterations: 1000. (The number of iterations of gradient descent)\n",
    "- Early stopping: This was set to \"true\" with a patience parameter of 20 iterations (that is, stop early if there's no improvement over the next 20 iterations). A validation fraction of 10% was used.\n",
    "- Solver: 'sgd' (stochastic gradient descent). This performed slightly better than 'Adam' (adaptive momentum) in initial searches, so was used for detailed searches.\n",
    "- Activation function: What nonlinear function to use in the hidden layers. I used 'relu' (rectified linear unit) after briefly exploring 'tanh' (hyperbolic tangent) too.\n",
    "\n",
    "**Hyperparameter Tuning:**\n",
    "- **Network Architecture**: I explored small 1 and 2 hidden layer networks of varying sizes\n",
    "- **alpha**: Controls the regularization strength\n",
    "- **learning_rate_init**: The initial value of the learning rate\n",
    "- **momentum**: Controls how much of previous updates is used in rate\n",
    "\n",
    "The optimal architecture used had two hidden layers of nonlinear (relu) units of 110 and 60 neurons. Other parameters that worked best were: alpha = 0.1, learning_rate_init = 0.02, and momentum = 0.95.\n",
    "\n",
    "After finding the best versions of each model with the data preprocessing outlined early (transforming skewed features, scaling), I explored individual models further to see if I could get any further performance improvement.\n",
    "\n",
    "Briefly:\n",
    "\n",
    "- **Logistic Regression**: I removed `density` from the input features (from the EDA, this had a high VIF, and was linearly dependent on other features). However, removing this feature caused the best F1 score to drop slightly.\n",
    "- **Random Forest**: I explored both removing the least important feature `wine_type` (feature importance is discussed in the next section), and removing some or all of the scaling. Very slightly better results were obtained with keeping all features, using standard scaling, but log transforming only `chlorides` (the F1 score crept above 0.84), but for practical purposes, the results are virtually identical. \n",
    "\n",
    "For simplicity - and to keep a level playing field - the results reported in the next section all use the same preprocessing applied to the data.\n",
    "\n",
    "### Brief Results Summary\n",
    "So - after all that tuning - how did the models actually do? The table below ranks the best models by weighted F1 score on the test set. It also shows the time spent on fitting the best model for each.\n",
    "\n",
    "This gives a preliminary ranking of Random Forest as the best, with Logistic Regression as the worst. As one would expect, Logistic Regression had the fastest run time, and the MLP the most expensive.\n",
    "\n",
    "| Model    | F1 Score | Test Accuracy | Time(s) |\n",
    "|----------|----------|---------------|---------|\n",
    "| rf       | 0.8366   | 0.8374        | 1.1     |\n",
    "| svm      | 0.8272   | 0.8280        | 3.3     |\n",
    "| mlp      | 0.8187   | 0.8430        | 4.4     |\n",
    "| logistic | 0.7683   | 0.7434        | 0.5     |\n",
    "\n",
    "It's worth first noting that none of the models is extremely accurate at classifying wines. The best is getting about 84% accuracy. However, this will still turn out to have practical use. \n",
    "\n",
    "The next section explores in more depth *how* each model is classifying wine data. It will turn out that the overall F1 score does not tell the complete picture, and that the models have very different qualities when it comes to how they are classifying wines. It also explores how the classifier might be used in practice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dcc59",
   "metadata": {},
   "source": [
    "# Results and Analysis\n",
    "\n",
    "The table below has a detailed summary of performance metrics for each model. As well as the weighted F1 score, the weighted precision and recall are given, as well as the precision and recall for each quality class (`regular` and `premium`). The terms \"precision\" and \"recall\" are usually used to refer to the positive (1) class observation - in this case `premium` wines. However here I felt it would be helpful to include those metrics for regular wines too, as well as the weighted average (weighting for class balance).\n",
    "\n",
    "|          |   Accuracy |   Weighted Precision |   Weighted Recall |   Weighted F1 |   Premium Precision |   Premium Recall |   Regular Precision |   Regular Recall |   Premium F1 |\n",
    "|:---------|-----------:|---------------------:|------------------:|--------------:|--------------------:|-----------------:|--------------------:|-----------------:|-------------:|\n",
    "| rf       |     0.8374 |               0.8359 |            0.8374 |        0.8366 |              0.5736 |           0.5594 |              0.8973 |           0.9026 |       0.5664 |\n",
    "| svm      |     0.828  |               0.8264 |            0.828  |        0.8272 |              0.5482 |           0.5347 |              0.8916 |           0.8968 |       0.5414 |\n",
    "| logistic |     0.7434 |               0.835  |            0.7434 |        0.7683 |              0.4083 |           0.7822 |              0.935  |           0.7343 |       0.5365 |\n",
    "| mlp      |     0.843  |               0.8257 |            0.843  |        0.8187 |              0.6882 |           0.3168 |              0.8579 |           0.9664 |       0.4339 |\n",
    "\n",
    "The model differences become clear looking at the recalls for each class. The recalls tell us, for each wine quality, what percentage of that quality the model got correct. Note that the logistic model - despite having the lowest F1 score, actually has the *highest* recall on premium wines. The differences between models are easier to see in a bar chart. \n",
    "\n",
    "![Model Recall Comparison](figures/Recall_Comparisons.png)\n",
    "\n",
    "*Recall for each Class for All Models*\n",
    "\n",
    "The chart shows:\n",
    "- Random Forest and SVM have similar patterns on each class. Both are correctly classifying about 90% of the regular wines, but under 60% of the premium wines. \n",
    "- Logistic Regression is correctly classifying between 75-80% of both. It is actually the best at identifying premium wines, but the least accurate overall, since it misclassifies so many regular wines.\n",
    "- The MLP - despite having similar overall F1 score to both the Random Forest and SVM - is actually behaving very differently internally. It is the poorest on premium wines (recall under 30%), but the best on regular wines (recall over 90%).\n",
    "\n",
    "The confusion matrices show this behavior in terms of totals. Here is the matrix for **Random Forest** (the SVM has a similar matrix but with a few fewer successes in each class).\n",
    "\n",
    "![Random Forest Confusion Matrix](figures/confusion_matrix_rf.png)  \n",
    "*Random Forest Confusion Matrix*\n",
    "\n",
    "For **Logistic Regression**, the total correctly classified premium wine is higher (bottom right) but the errors on regular wines is much higher (top right).\n",
    "\n",
    "![Logistic Regression Confusion Matrix](figures/confusion_matrix_logistic.png)  \n",
    "*Logistic Regression Confusion Matrix*\n",
    "\n",
    "The **MLP** has very few errors on regular wines (top right) but a lot of errors on premium wines (bottom left).\n",
    "\n",
    "![MLP Confusion Matrix](figures/confusion_matrix_mlp.png)  \n",
    "*MLP Confusion Matrix*\n",
    "\n",
    "In summary, the Random Forest (and the SVM) both have a similar balance in terms of classification errors. The MLP tends to overclassify wines as `regular`, and Logistic Regression is the opposite. It is best at correctly classifying `premium` wines, but has a lot of false positives. Overall, the Random Forest has the best performance. An added advantage is some capability to explore which features are most important.\n",
    "\n",
    "## Feature Importance\n",
    "\n",
    "What insights do the models give on what features are relevant to wine quality? I used the Random Forest's feature importance. This measures how much each feature contributed to reducing classification uncertainty (in terms of Gini impurity) across the entire forest.\n",
    "\n",
    "| Feature | Importance |\n",
    "|---------|------------|\n",
    "| alcohol | 0.222987 |\n",
    "| density | 0.119376 |\n",
    "| chlorides | 0.092531 |\n",
    "| volatile acidity | 0.092127 |\n",
    "| total sulfur dioxide | 0.075486 |\n",
    "| citric acid | 0.073331 |\n",
    "| sulphates | 0.072998 |\n",
    "| pH | 0.068285 |\n",
    "| residual sugar | 0.063973 |\n",
    "| free sulfur dioxide | 0.062964 |\n",
    "| fixed acidity | 0.052781 |\n",
    "| wine_type | 0.003161 |\n",
    "\n",
    "The most important feature was alcohol, and the least was the type of wine (red or white). However, removing wine type caused performance to drop slightly to about 82%, so although it was the least important feature, it was necessary to get the best performance. \n",
    "\n",
    "All models have used the default threshold of 0.5. That is, if the output is a probability of 0.5 or greater, the wine is classed as `premium`. What would the effect on the model be of adjusting this threshold? The next section looks at the Receiver Operating Characteristic (ROC) curve. \n",
    "\n",
    "## Adjusting Model Thresholds\n",
    "\n",
    "The plot below shows the ROC curve for each model, as well as the area under the curve (AUC). The curve plots the True Positive Rate as a function of the False Positive Rate as the threshold (or cutoff) probability for predicting a \"1\" (premium wine) vs \"0\" is adjusted. It does not show the thresholds themselves directly, but shows the overall profile of the model in response to tuning the threshold.  A good model should curve as close as possible to the top left, meaning that as the threshold is adjusted to get more True Positives (that is, correctly identify a higher proportion of premium wines), the False Positive rate stays low. Randomly guessing would fall along the diagonal.\n",
    "\n",
    "![ROC Curve](figures/ROC.png)\n",
    "*The ROC Curve for the best of each of the four Models*\n",
    "\n",
    "## Performance Summary and Implications\n",
    "\n",
    "For the problem as a whole, identifying `regular` wines seems easier (the best models had about 90% recall) than identifying `premium` wines (even the best model - logistic - achieved only 78% recall). It appears that identifying premium (that is, above average in quality) is complex.\n",
    "\n",
    "All things considered, the Random Forest was the best classifier - narrowly beating out the MLP - in terms of F1 score. It also was the most stable in terms of threshold tuning, generally being in the top two classifiers. Additionally it - unlike the MLP - gives some insight into what features are most important. It has a recall of about 90% on regular wines, but only 56% on premium wines.\n",
    "\n",
    "The next section explores whether such a model would be useful in practice - given its mediocre performance on `premium` wines. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb08b2",
   "metadata": {},
   "source": [
    "# Discussion: Is the Best Model Actually Useful?\n",
    "\n",
    "I have to honestly admit that during the tuning process I found the performance of the models on `premium` wines disappointing. However, let's see if it can still be useful in practice by exploring a potential application using the data and model from above.\n",
    "\n",
    "Suppose a wine importer wants to identify premium wines - wines that have been highly rated by wine experts, and thus can be priced higher. If they chose a wine at random they have a 19% chance of choosing a premium wine.\n",
    "\n",
    "However, suppose instead they use the Random Forest as regular wine pre-filter. That is, rather than importing a randomly chosen wine, they feed the wine's physical and chemical measurements - assuming these are available - into the trained Random Forest classifier. They only import the wine for assessment by their own wine tasters if the Random Forest classifies it as `premium`.\n",
    "\n",
    "Using a Bayesian approach (Reich et al., 2019), let's look at how using the classifier in this way changes the probability of choosing a premium wine.\n",
    "\n",
    "The \"prior\" probabilities (before using the classifier) are P(Regular) = 0.81, P(Premium) = 0.19. \n",
    "\n",
    "Let the events \"classifier labels the wine as premium\" and \"classifier labels the wine as regular\" be denoted simply by 1 and 0 respectively.\n",
    "\n",
    "To calculate the \"posterior\" probability that the wine is a premium wine given that the classifier labeled it as such - that is P(Premium|1) - Bayes' theorem can be used.\n",
    "\n",
    "Briefly, Bayes' theorem stipulates:\n",
    "\n",
    "$P(A \\mid B) = \\frac{P(B \\mid A)\\,P(A)}{P(B)}$\n",
    "\n",
    "In this case, the numerator is:   \n",
    "\n",
    "P(1 | Premium)P(Premium) = (0.56 × 0.19) = 0.1064\n",
    "\n",
    "For the denominator:\n",
    "\n",
    "P(1) = P(1 | Premium)P(Premium) + P(1 | Regular)P(Regular) \n",
    "\n",
    "P(1) = (0.56 × 0.19) + (0.10 × 0.81) = 0.1874\n",
    "\n",
    "Plugging these into Bayes' Theorem gives:\n",
    "\n",
    "P(Premium | 1) = 0.1064 / 0.1874 = 0.568 \n",
    "\n",
    "So, the \"posterior\" probability P(Premium | 1) - the probability that the wine is a premium wine given that the Random Forest classified it as a \"1\" (a premium wine) - is approximately 57%. \n",
    "\n",
    "In other words, using the classifier to screen out regular wines improves the chances of selecting a premium wine from 19% to 57% - a threefold improvement. \n",
    "\n",
    "Put in large scale terms, if the importer wants to find (say) 500 premium wine brands, how many wines would they expect to have to import in each case?\n",
    "\n",
    "If Y is a random variable representing the number of wines imported, r is the desired number of successes (in this case, the number of premium wines we want), and p the probability of a success on each trial, then Y has a \"negative binomial\" distribution. The expected value of Y is simply r/p. Plugging numbers in, we expected to have to import\n",
    "\n",
    "E(Y) = 500/0.19 ≈ 2,632\n",
    "\n",
    "wines without using the classifier, and \n",
    "\n",
    "E(Y) = 500/0.568 ≈ 880\n",
    "\n",
    "wines using the classifier. The importer only needs to import about one-third as many wines (on average) to achieve their goal of 500 premium wines! \n",
    "\n",
    "Of course, there are many caveats: enough high quality data would have to be available - including expert ratings - from the region we are importing from. Wine importers would not be selecting at random but would have domain expertise to guide them, and so on. But this analysis shows that a machine learning approach at least has the *potential* to be a valuable tool as part of the process for making wine importation more efficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bb9e9",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, the problem of classifying wines by their physical and chemical properties into taste quality categories was explored. Four machine learning models were tested: one linear model (Logistic Regression) and three nonlinear models (Random Forest, Support Vector Machine, and Multi-Layer Perceptron). After extensive hyperparameter tuning, the Random Forest was found to be the best performing model. While it was more accurate on regular wines than premium wines, its overall recall was sufficient to be potentially useful as a screener for wine importers looking to increase their chances of selecting premium wines.\n",
    "\n",
    "Overall lessons learned:\n",
    "\n",
    "• **Data quality matters, even from reputable sources.** While this dataset was generally clean, it unexpectedly contained many duplicates of unknown provenance that had to be removed prior to modeling.\n",
    "\n",
    "• **Target class imbalance requires careful handling in supervised machine learning.** The original data had several quality levels with very few examples. Reframing the problem as a binary classification with balanced classes resulted in a problem with enough examples for useful results.\n",
    "\n",
    "• **Look beyond surface-level metrics.** It was critical to go beyond the F1 scores and dig deeper into how models were performing their classifications. The superficial similarity of some F1 scores masked crucial differences in how the models were splitting the two classes internally.\n",
    "\n",
    "• **Even imperfect models can have practical value.** Identifying premium wines turned out to be a subtle problem, and all models struggled with achieving high recall on the premium class. However, a Bayesian analysis showed that the best model would be potentially useful as a screening filter for regular wines. This shows the importance of thinking about model performance not just in terms of metrics like F1 scores, but in terms of how the models could be used in practice.\n",
    "\n",
    "More generally, I feel that the project was a valuable experience in taking a real-world data set through the entire supervised learning lifecycle, and in the process building the infrastructure needed to support fine-tuning and comparing multiple models on the same data set.\n",
    "\n",
    "Thank you for reading, and I look forward to your feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c9099",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Bunevičius, V. (2019). Wine Quality: A Machine Learning Case Study. Retrieved September 10, 2025, from https://bunevicius.com/projects/red-wine/index.html\n",
    "\n",
    "Cortez, P., Cerdeira, A., Almeida, F., Matos, T., & Reis, J. (2009). Modeling wine preferences by data mining from physicochemical properties. *Decision Support Systems*, 47(4), 547–553. https://doi.org/10.1016/j.dss.2009.05.016\n",
    "\n",
    "Faraway, J. J. (2014). *Linear models with R* (2nd ed., pp. 106-109). CRC Press.\n",
    "\n",
    "Ijemuah, V. (2020). Wine Quality Prediction using Machine Learning. *Medium*. Retrieved September 10, 2025, from https://medium.com/@ijemuahvictoria/wine-quality-prediction-using-machine-learning-c0b3b427693e\n",
    "\n",
    "James, G., Witten, D., Hastie, T., Tibshirani, R., & Taylor, J. (2021). *An Introduction to Statistical Learning: With Applications in R* (2nd ed.). Springer.\n",
    "\n",
    "Reich, B. J., & Ghosh, S. K. (2019). *Bayesian Statistical Methods* (1st ed.). Chapman & Hall/CRC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f4107f",
   "metadata": {},
   "source": [
    "# Appendix A: AI Usage\n",
    "\n",
    "Claude Sonnet 4.1 was used in a variety of ways within this project, within the \"limited\" usage guidelines as set out in the course. This section gives details, and additional steps where necessary to ensure the guidelines were adhered to.\n",
    "\n",
    "- For project management, keeping tasks, time estimates, and maintaining a checklist of what was done and what was left.\n",
    "- For research on the reason for missing values in the dataset, and any additional research that has been done with the dataset.\n",
    "- For domain research, as specified in the EDA section.\n",
    "- For proofreading and editing the final report. The prompt used for this thread:\n",
    "\n",
    "  *\"This thread is for Drafting my conclusions and proofreading the report. In the thread I will appreciate your help with basic edits for clarity and cohesion while maintaining my voice. Please do not add any additional opinions or domain expertise. This is important so that I maintain academic integrity. Even if the result is less than perfect in terms of language I would rather that, than something that's perfect and inauthentic.\"*\n",
    "\n",
    "- Formatting tables, references and other organizational tasks in preparing the report\n",
    "\n",
    "- As a sounding board to discuss modeling results during the modeling and tuning process. In these discussions I asked the tool to play the role of a supportive professor that would challenge me and help me gain a deeper understanding. \n",
    "\n",
    "- Prior to this term, I used Claude to explore model pipelining design and development principles. With its assistance I developed a basic modeling pipeline suitable for comparing the performance of multiple models on a classification problem. For this project - in order to adhere to the new AI usage guidelines - I took several weeks to refactor and rebuild a simpler pipeline. In particular, I designed and built `WineConfig` and `WineModelPipeline` classes - the core components of the system, using the insights I had gained from the previous research, but starting from my own specifications and templates. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62f096",
   "metadata": {},
   "source": [
    "# Appendix B: Sample Parameter Dictionary\n",
    "\n",
    "## Base Parameters (Kept Constant During Grid Search)\n",
    "```python\n",
    "self.model_base_params = {\n",
    "    'logistic': {\n",
    "        'penalty': 'l2',\n",
    "        'max_iter': 1000,\n",
    "        'solver': 'saga',  \n",
    "        'class_weight': 'balanced', \n",
    "        'n_jobs': -1,  # use all available cores for parallel processing\n",
    "        'random_state': self.random_state\n",
    "    },\n",
    "    'rf': {\n",
    "        'class_weight': 'balanced',\n",
    "        'n_jobs': -1,  # use all available cores for parallel processing\n",
    "        'random_state': self.random_state\n",
    "    },\n",
    "    'svm': {\n",
    "        'kernel': 'rbf',\n",
    "        'class_weight': 'balanced',\n",
    "        'probability': True,   # This stores probabilities of class labels as well as predictions for AUC etc\n",
    "        'random_state': self.random_state\n",
    "        # Note: svm doesn't support n_jobs\n",
    "    },\n",
    "    'mlp': {\n",
    "        'max_iter': 1000,\n",
    "        'early_stopping': True,\n",
    "        'validation_fraction': 0.1,\n",
    "        'n_iter_no_change': 20,  # Patience parameter - how long to keep going with no improvement\n",
    "        'random_state': self.random_state\n",
    "        # Note: MLP doesn't support balanced class_weight or n_jobs\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "## Grid Search Parameters\n",
    "\n",
    "This grid is from an early rough grid search.\n",
    "\n",
    "```python\n",
    "self.model_grid_params = {\n",
    "    'logistic': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    'rf': {\n",
    "        'n_estimators': [50, 100, 200, 300, 400, 500],\n",
    "        'max_depth': [5, 10, 15, 20, 25, 30, None],\n",
    "        'max_features': ['sqrt']\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': [0.01, 0.1, 1.0, 10, 100]\n",
    "    },\n",
    "    'mlp': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (150,), (200,), (100, 50)],\n",
    "        'alpha': [0.001, 0.01, 0.1],\n",
    "        'learning_rate_init': [0.001, 0.01, 0.02]\n",
    "    }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
